{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ba3f58-a7f0-49d6-85b9-64eed17a2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.418 | LB: 0.072 | Router: 1.295 | Entropy: 1.247\n",
      "[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [627, 138, 516, 719]\n",
      "[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2396836280822754, 0.20570972561836243, 0.2349652498960495, 0.3196414113044739]\n",
      "[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.361 | LB: 0.015 | Router: 1.358 | Entropy: 1.350\n",
      "[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [666, 89, 231, 1014]\n",
      "[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2457910031080246, 0.2177312970161438, 0.23370280861854553, 0.30277499556541443]\n",
      "[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.323 | LB: 0.015 | Router: 1.333 | Entropy: 1.346\n",
      "[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [626, 107, 318, 949]\n",
      "[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2408578097820282, 0.22088824212551117, 0.2361108511686325, 0.3021431565284729]\n",
      "[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.271 | LB: 0.016 | Router: 1.276 | Entropy: 1.326\n",
      "[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [598, 129, 355, 918]\n",
      "[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24361948668956757, 0.22048905491828918, 0.2351730465888977, 0.3007183372974396]\n",
      "[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.223 | LB: 0.018 | Router: 1.200 | Entropy: 1.281\n",
      "[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [567, 196, 378, 859]\n",
      "[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24517381191253662, 0.22319447994232178, 0.23227833211421967, 0.29935339093208313]\n",
      "\n",
      "[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent\n",
      "tensor([[297,  58,  43,  79],\n",
      "        [110, 156,  24,  48],\n",
      "        [ 40,  23, 285,  60],\n",
      "        [125, 112, 112, 428]])\n",
      "[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.5192307692307693, 0.44412607449856734, 0.6142241379310345, 0.6959349593495935]\n",
      "[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 572, 1: 349, 2: 464, 3: 615}\n",
      "\n",
      "[Agentic][Static Routing] Agent outputs BEFORE:\n",
      "[Agentic] Agent 0 output: [[ 0.18854988 -0.63583314 -0.2946814   0.31569844]]\n",
      "[Agentic] Agent 1 output: [[0.09884851 0.22254989 0.1946752  0.26245126]]\n",
      "[Agentic] Agent 2 output: [[-0.83836895 -1.1631118   1.2584822   0.2695332 ]]\n",
      "[Agentic] Agent 3 output: [[-0.5242375  -0.4091273  -0.44803646  0.5635157 ]]\n",
      "\n",
      "[Agentic][Static Routing][Training] Agent 0 fine-tuning ...\n",
      "[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 40.005\n",
      "[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 0.819\n",
      "[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.220\n",
      "\n",
      "[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:\n",
      "[Agentic] Agent 0 output: [[ 4.654058  -4.1888223 -4.13238   -3.0432615]]\n",
      "[Agentic] Agent 1 output: [[0.09884851 0.22254989 0.1946752  0.26245126]]\n",
      "[Agentic] Agent 2 output: [[-0.83836895 -1.1631118   1.2584822   0.2695332 ]]\n",
      "[Agentic] Agent 3 output: [[-0.5242375  -0.4091273  -0.44803646  0.5635157 ]]\n",
      "[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.9112426035502958, 0.9338235294117647, 1.0]\n",
      "\n",
      "[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):\n",
      "[Agentic][CAC] Individual Agent 0 output: tensor([[ 3.9724, -3.7572, -3.3710, -2.4644]])\n",
      "[Agentic][CAC] Individual Agent 1 output: tensor([[-0.0176,  0.1097,  0.2423,  0.1614]])\n",
      "[Agentic][CAC] Individual Agent 2 output: tensor([[-0.5941, -1.0641,  1.3857, -0.1762]])\n",
      "[Agentic][CAC] Individual Agent 3 output: tensor([[-0.7977, -0.2917, -0.0368,  0.1457]])\n",
      "[Agentic][CAC] Mean (raw logits) predicted class: 0\n",
      "\n",
      "[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:\n",
      "\n",
      "[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...\n",
      "[Agentic][CAC][SharedMemory] Updating memory for agent 1.\n",
      "[Agentic][CAC][SharedMemory] Updating memory for agent 3.\n",
      "[Agentic][CAC] Aggregated output (learnable selection): tensor([[[-0.4077, -0.0910,  0.1027,  0.1536]]])\n",
      "[Agentic] Agents selected by coordinator: [1, 3]\n",
      "[Agentic][CAC] Selected Agent 1 output: tensor([[-0.0176,  0.1097,  0.2423,  0.1614]])\n",
      "[Agentic][CAC] Selected Agent 3 output: tensor([[-0.7977, -0.2917, -0.0368,  0.1457]])\n",
      "[Agentic][CAC] Mean (raw logits) predicted class: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)\n",
    "# torch.manual_seed(42)\n",
    "# torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 1. Load AG News data\n",
    "dataset = load_dataset('ag_news', split='train[:2000]')  # Keep it small for demo\n",
    "\n",
    "# 2. Build a simple vocab\n",
    "tokenizer = lambda s: s.lower().split()  # Replace with better tokenizer if needed\n",
    "vocab = build_vocab_from_iterator((tokenizer(x['text']) for x in dataset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 3. Encode samples\n",
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return torch.tensor([vocab[token] for token in tokens][:8], dtype=torch.long)  # seq_len=8\n",
    "    \n",
    "\n",
    "X = [encode(sample['text']) for sample in dataset]\n",
    "X = pad_sequence(X, batch_first=True, padding_value=0)  # Pad to max len in batch (or use fixed len)\n",
    "\n",
    "# 4. Prepare labels and agent assignments\n",
    "y = torch.tensor([sample['label'] for sample in dataset])\n",
    "user_ids = y  # Assign agent per news category\n",
    "n_samples = len(X)\n",
    "\n",
    "# --------- 2. Model Components ---------\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, n_heads):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, model_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 10, model_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=n_heads, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_embedding[:, :x.size(1)]\n",
    "        out = self.encoder(x)\n",
    "        return out[:, 0, :]\n",
    "        \n",
    "class AgentFFN(nn.Module):\n",
    "    def __init__(self, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class RoutingNetwork(nn.Module):\n",
    "    def __init__(self, model_dim, n_agents):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(model_dim, n_agents)\n",
    "    def forward(self, features):\n",
    "        logits = self.linear(features)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        return logits, probs\n",
    "\n",
    "class AssignmentModule:\n",
    "    def __init__(self, n_agents):\n",
    "        self.n_agents = n_agents\n",
    "\n",
    "    def __call__(self, user_id):\n",
    "        # Assign agent by rule: user_id % n_agents (can be extended)\n",
    "        if isinstance(user_id, torch.Tensor):\n",
    "            return (user_id % self.n_agents).item() \n",
    "        else:\n",
    "            return user_id % self.n_agents\n",
    "\n",
    "class DualRoutingModule(nn.Module):\n",
    "    def __init__(self, model_dim, n_agents, agents):\n",
    "        super().__init__()\n",
    "        self.routing_network = RoutingNetwork(model_dim, n_agents)\n",
    "        self.assignment_module = AssignmentModule(n_agents)\n",
    "        self.agents = agents  # nn.ModuleList of AgentFFN\n",
    "\n",
    "    def forward(self, features, user_id=None, mode='dynamic', return_routing=False):\n",
    "        \"\"\"\n",
    "        features: (batch, model_dim)\n",
    "        user_id: for static routing\n",
    "        mode: 'dynamic' or 'static'\n",
    "        return_routing: if True, return logits/probs (dynamic only)\n",
    "        Returns:\n",
    "            outputs: (batch, out_dim)\n",
    "            (optional: logits, probs for dynamic)\n",
    "        \"\"\"\n",
    "        batch_size = features.size(0)\n",
    "        outputs = []\n",
    "        if mode == 'dynamic':\n",
    "            logits, probs = self.routing_network(features)\n",
    "            agent_indices = torch.argmax(probs, dim=-1)  # (batch,)\n",
    "            for i in range(batch_size):\n",
    "                ai = agent_indices[i].item()\n",
    "                outputs.append(self.agents[ai](features[i:i+1]))\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            if return_routing:\n",
    "                return outputs, logits, probs\n",
    "            else:\n",
    "                return outputs\n",
    "        elif mode == 'static':\n",
    "            assert user_id is not None, \"user_id required for static routing\"\n",
    "            agent_idx = self.assignment_module(user_id)\n",
    "            out = self.agents[agent_idx](features)\n",
    "            return out\n",
    "        else:\n",
    "            raise ValueError(\"[Agentic] mode must be 'dynamic' or 'static'\")\n",
    "\n",
    "class AgenticTransformerDualRouting(nn.Module):\n",
    "    def __init__(self, n_agents, vocab_size, model_dim, out_dim, n_heads=2):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone(vocab_size, model_dim, n_heads=n_heads)\n",
    "        agents = nn.ModuleList([AgentFFN(model_dim, out_dim) for _ in range(n_agents)])\n",
    "        self.dual_routing_module = DualRoutingModule(model_dim, n_agents, agents)\n",
    "\n",
    "    def forward(self, x, user_id=None, mode='dynamic', return_routing=False):\n",
    "        shared = self.backbone(x)  # (batch, model_dim)\n",
    "        return self.dual_routing_module(shared, user_id=user_id, mode=mode, return_routing=return_routing)\n",
    "\n",
    "# class SimpleLearnableCoordinator(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Minimal learnable coordinator: for demonstration, returns a fixed or randomly chosen subset of agent_ids.\n",
    "#     Replace logic as needed for your application.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_agents, n_select=2):\n",
    "#         super().__init__()\n",
    "#         self.n_agents = n_agents\n",
    "#         self.n_select = n_select\n",
    "#         self.selector = nn.Linear(1, n_agents)  # Just a dummy for illustration\n",
    "\n",
    "#     def forward(self, x, agent_ids):\n",
    "#         # For demonstration: randomly select n_select agents (could use logits from self.selector)\n",
    "#         if len(agent_ids) <= self.n_select:\n",
    "#             return agent_ids\n",
    "#         selected = torch.randperm(len(agent_ids))[:self.n_select].tolist()\n",
    "#         return [agent_ids[i] for i in selected]\n",
    "\n",
    "class LearnableCoordinator(nn.Module):\n",
    "    def __init__(self, model_dim, n_agents, n_select=2):\n",
    "        super().__init__()\n",
    "        self.n_agents = n_agents\n",
    "        self.n_select = n_select\n",
    "        self.selector = nn.Linear(model_dim, n_agents)  # Takes backbone features\n",
    "\n",
    "    def forward(self, features, agent_ids):\n",
    "        # features: (batch, model_dim) or (model_dim,) if batch=1\n",
    "        if features.dim() == 1:\n",
    "            features = features.unsqueeze(0)\n",
    "        logits = self.selector(features)  # (batch, n_agents)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        # Select top-k agents for each input in the batch\n",
    "        selected_indices = torch.topk(probs, self.n_select, dim=-1).indices\n",
    "        # Convert indices to agent IDs for each batch item\n",
    "        selected_agents = []\n",
    "        for i in range(features.size(0)):\n",
    "            selected_agents.append([agent_ids[j] for j in selected_indices[i].tolist()])\n",
    "        return selected_agents  # list of list of agent IDs (per batch)\n",
    "\n",
    "class CAC:\n",
    "    def __init__(self, model, coordinator=None, workflow=None):\n",
    "        self.model = model\n",
    "        self.shared_memory = {}\n",
    "        self.coordinator = coordinator      # Should be a callable (e.g., a neural net)\n",
    "        self.workflow = workflow            # List of agent IDs (workflow order)\n",
    "\n",
    "    def communicate(self, outputs, protocol=None):\n",
    "        communicated = []\n",
    "        for idx, out in enumerate(outputs):\n",
    "            # Example metadata: agent index, completion status, dummy confidence\n",
    "            metadata = {\n",
    "                'agent_idx': idx,\n",
    "                'status': 'complete',\n",
    "                'confidence': float(torch.rand(1))  # Simulated confidence\n",
    "            }\n",
    "            # Structured message (could be JSON serializable)\n",
    "            message = {\n",
    "                'output': out,\n",
    "                'metadata': metadata\n",
    "            }\n",
    "            # Example rule: Only share if confidence > threshold (can set via protocol)\n",
    "            threshold = protocol.get('confidence_threshold', 0.0) if protocol else 0.0\n",
    "            if metadata['confidence'] > threshold:\n",
    "                print(f\"[Agentic][CAC][Communicate] Sharing Agent {idx} output with confidence {metadata['confidence']:.2f}\")\n",
    "                communicated.append({'output': out, 'metadata': {'agent_idx': idx}})\n",
    "            else:\n",
    "                print(f\"[Agentic][CAC][Communicate] Agent {idx} output NOT shared (confidence {metadata['confidence']:.2f})\")\n",
    "        # Return only the outputs for downstream processing\n",
    "        return [msg['output'] for msg in communicated]\n",
    "\n",
    "    def update_shared_memory(self, agent_id, data):\n",
    "        print(f\"[Agentic][CAC][SharedMemory] Updating memory for agent {agent_id}.\")\n",
    "        self.shared_memory[agent_id] = data\n",
    "\n",
    "    # def decompose_and_route(self, x, agents=[0,1,2,3], vocab=None):\n",
    "    #     # If x is a dict and 'text' present, do AG News-specific split\n",
    "    #     if isinstance(x, dict) and 'text' in x:\n",
    "    #         assert vocab is not None, \"vocab must be provided for raw article input\"\n",
    "    #         text = x['text']\n",
    "    #         # Naive headline/body split\n",
    "    #         parts = text.split('.', 1)\n",
    "    #         headline = parts[0]\n",
    "    #         body = parts[1] if len(parts) > 1 else \"\"\n",
    "            \n",
    "    #         def encode_text(txt):\n",
    "    #             tokens = [vocab[token] for token in txt.lower().split()][:8]\n",
    "    #             if len(tokens) == 0:\n",
    "    #                 tokens = [vocab['<unk>']]  # Fallback: single unknown token\n",
    "    #             return pad_sequence(\n",
    "    #                 [torch.tensor(tokens, dtype=torch.long)],\n",
    "    #                 batch_first=True,\n",
    "    #                 padding_value=0\n",
    "    #             )\n",
    "\n",
    "    #         headline_encoded = encode_text(headline)\n",
    "    #         body_encoded = encode_text(body)\n",
    "            \n",
    "    #         subtasks = [headline_encoded, body_encoded]\n",
    "    #         routed_agents = [agents[0], agents[1]]\n",
    "            \n",
    "    #         # Optionally, expand to agents 2 and 3 for more complex coordination\n",
    "    #         if len(agents) > 2:\n",
    "    #             subtasks.append(body_encoded)       # or another aspect (e.g., summary)\n",
    "    #             routed_agents.append(agents[2])\n",
    "    #         if len(agents) > 3:\n",
    "    #             subtasks.append(headline_encoded)   # or another aspect (e.g., sentiment)\n",
    "    #             routed_agents.append(agents[3])\n",
    "    #         return subtasks, routed_agents\n",
    "    #     else:\n",
    "    #         # Fallback: just send x to all agents (standard CAC pattern)\n",
    "    #         xs = [x for _ in agents]\n",
    "    #         return xs, agents\n",
    "\n",
    "    # def aggregate(self, outputs, method='mean'):\n",
    "    #     if method == 'mean':\n",
    "    #         return torch.mean(torch.stack(outputs, dim=0), dim=0)\n",
    "    #     elif method == 'majority':\n",
    "    #         preds = [out.argmax(dim=-1).item() for out in outputs]\n",
    "    #         return max(set(preds), key=preds.count)\n",
    "    #     elif method == 'softmax_mean':\n",
    "    #         probs = [F.softmax(out, dim=-1) for out in outputs]\n",
    "    #         mean_probs = torch.mean(torch.stack(probs, dim=0), dim=0)\n",
    "    #         return mean_probs.argmax(dim=-1).item()\n",
    "    #     else:\n",
    "    #         raise NotImplementedError(f\"Aggregation '{method}' not supported.\")\n",
    "\n",
    "    def forward(self, x, agent_ids, user_id=None, mode='static', aggregation='mean'):\n",
    "        # Get features from frozen backbone\n",
    "        with torch.no_grad():\n",
    "            features = self.model.backbone(x)  # (batch, model_dim)\n",
    "\n",
    "        # # Workflow-based coordinator takes precedence if defined\n",
    "        # if self.workflow is not None:\n",
    "        #     print(\"\\n[Workflow Coordinator] Using specified workflow:\", self.workflow)\n",
    "        #     agent_ids = self.workflow\n",
    "        # # Otherwise, use learnable coordinator if defined\n",
    "        # elif self.coordinator is not None:\n",
    "        #     print(\"\\n[Learnable Coordinator] Selecting agents dynamically...\")\n",
    "        #     selected_agents = self.coordinator(features, agent_ids)\n",
    "        # else:\n",
    "        #     selected_agents = [agent_ids for _ in range(x.size(0))]  # fallback: all agents\n",
    "\n",
    "        if self.coordinator is not None:\n",
    "            print(\"\\n[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...\")\n",
    "            selected_agents = self.coordinator(features, agent_ids)\n",
    "        else:\n",
    "            selected_agents = [agent_ids for _ in range(x.size(0))]  # fallback: all agents\n",
    "\n",
    "        # xs, agent_ids = self.decompose_and_route(x, agent_ids)\n",
    "\n",
    "        outputs = []\n",
    "        # For each sample in batch\n",
    "        for i in range(x.size(0)):\n",
    "            sample_outputs = []\n",
    "            for agent_id in selected_agents[i]:\n",
    "                out = self.model.dual_routing_module.agents[agent_id](features[i].unsqueeze(0))\n",
    "                self.update_shared_memory(agent_id, out)\n",
    "                sample_outputs.append(out)\n",
    "            # Aggregate outputs for this sample (mean)\n",
    "            sample_agg = torch.mean(torch.stack(sample_outputs, dim=0), dim=0)\n",
    "            outputs.append(sample_agg)\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        return outputs        \n",
    "# --------- 3. Model Initialization ---------\n",
    "\n",
    "# After building vocab and preparing X, y, user_ids:\n",
    "n_agents = 4                       # AG News has 4 classes (World, Sports, Business, Sci/Tech)\n",
    "vocab_size = len(vocab)            # Set vocab_size to the size of your vocab\n",
    "model_dim = 32                     # (or another dimension—keep consistent with model)\n",
    "out_dim = 4                        # Number of classes in AG News\n",
    "\n",
    "# Now initialize the model as before:\n",
    "model = AgenticTransformerDualRouting(n_agents, vocab_size, model_dim, out_dim)\n",
    "clf_loss_fn = nn.CrossEntropyLoss()\n",
    "router_loss_fn = nn.CrossEntropyLoss()  # Supervision: agent == class\n",
    "lb_lambda = 0.01  # load-balancing\n",
    "router_lambda = 1.0  # supervised router\n",
    "\n",
    "\n",
    "# --------- 4. Joint Training (Dynamic Routing) ---------\n",
    "lb_lambda = 3  # load balancing weight\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Add this before your loop\n",
    "entropy_lambda = 0.05  # You can tune this value; start small!\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_ce = 0\n",
    "    total_lb = 0\n",
    "    total_router = 0\n",
    "    total_entropy = 0\n",
    "    routing_counts = [0 for _ in range(n_agents)]\n",
    "    agent_probs_sum = torch.zeros(n_agents)\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "        X_batch = X[batch_start:batch_start+batch_size]\n",
    "        y_batch = y[batch_start:batch_start+batch_size]\n",
    "        out, logits, probs = model(X_batch, user_id=None, mode='dynamic', return_routing=True)\n",
    "        # Main classification loss\n",
    "        ce_loss = clf_loss_fn(out, y_batch)\n",
    "        # Supervised router loss: force router to send label i to expert i\n",
    "        router_loss = router_loss_fn(logits, y_batch)\n",
    "        # Load balancing (softmax entropy penalty)\n",
    "        probs_mean = probs.mean(dim=0)\n",
    "        lb_loss = ((probs_mean - 1.0/n_agents) ** 2).sum()\n",
    "        # Entropy regularization (maximize entropy)\n",
    "        entropy = -torch.sum(probs * torch.log(probs + 1e-8), dim=1).mean()\n",
    "        # Total loss\n",
    "        loss = ce_loss + router_lambda * router_loss + lb_lambda * lb_loss + entropy_lambda * entropy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_ce += ce_loss.item() * X_batch.size(0)\n",
    "        total_router += router_loss.item() * X_batch.size(0)\n",
    "        total_lb += lb_loss.item() * X_batch.size(0)\n",
    "        total_entropy += entropy.item() * X_batch.size(0)\n",
    "        # Routing stat\n",
    "        routed = probs.argmax(dim=-1)\n",
    "        for idx in routed.tolist():\n",
    "            routing_counts[idx] += 1\n",
    "        agent_probs_sum += probs.sum(dim=0).detach()\n",
    "    print(f\"[Agentic][Dynamic Routing][Training] Epoch {epoch+1} | CE: {total_ce/n_samples:.3f} | LB: {total_lb/n_samples:.3f} | Router: {total_router/n_samples:.3f} | Entropy: {total_entropy/n_samples:.3f}\")\n",
    "    print(\"[Agentic][Dynamic Routing][Training] Hard assignment counts per agent:\", routing_counts)\n",
    "    print(\"[Agentic][Dynamic Routing][Training] Mean softmax probability per agent:\", (agent_probs_sum / n_samples).tolist())\n",
    "\n",
    "# 4. Per-agent accuracy (using only samples routed to that agent)\n",
    "def evaluate_per_agent_handled(model, X, y, handled_by, n_agents, mode):\n",
    "    per_agent_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for agent in range(n_agents):\n",
    "            idxs = [i for i, assigned in enumerate(handled_by) if assigned == agent]\n",
    "            if len(idxs) == 0:\n",
    "                per_agent_acc.append(float('nan'))\n",
    "                continue\n",
    "            correct = 0\n",
    "            for i in idxs:\n",
    "                if mode == 'dynamic':\n",
    "                    out = model(X[i].unsqueeze(0), mode=mode)\n",
    "                else:\n",
    "                    out = model(X[i].unsqueeze(0), user_id=agent, mode=mode)\n",
    "                pred = out.argmax(dim=1).item()\n",
    "                correct += int(pred == y[i].item())\n",
    "            per_agent_acc.append(correct / len(idxs))\n",
    "    return per_agent_acc\n",
    "    \n",
    "\n",
    "# 5. Confusion Matrix (True class vs Routed agent)\n",
    "conf_mat = torch.zeros((n_agents, n_agents), dtype=torch.long)\n",
    "model.eval()\n",
    "all_routed = []\n",
    "with torch.no_grad():\n",
    "    for i in range(n_samples):\n",
    "        _, logits, probs = model(X[i].unsqueeze(0), return_routing=True)\n",
    "        routed_agent = probs.argmax(dim=-1).item()\n",
    "        conf_mat[y[i], routed_agent] += 1\n",
    "        all_routed.append(routed_agent)\n",
    "print(\"\\n[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent\")\n",
    "print(conf_mat)\n",
    "\n",
    "# all_routed should already be a list of agent assignments by the router for each sample\n",
    "per_agent_acc_dynamic = evaluate_per_agent_handled(model, X, y, all_routed, n_agents, mode='dynamic')\n",
    "print(\"[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples):\", per_agent_acc_dynamic)\n",
    "\n",
    "unique, counts = torch.tensor(all_routed).unique(return_counts=True)\n",
    "dist = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "print(f\"[Agentic][Dynamic Routing][Testing] Final routing distribution: {dist}\")\n",
    "# --------- 5. Post-Deployment: Freeze backbone and other agents ---------\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "target_agent = 0\n",
    "for i, agent in enumerate(model.dual_routing_module.agents):\n",
    "    if i != target_agent:\n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# --------- 6. Independent Fine-Tuning for Agent 0 (Static Routing) ---------\n",
    "def print_agent_outputs(model, X, n_agents):\n",
    "    for agent_id in range(n_agents):\n",
    "        out = model(X[0].unsqueeze(0), user_id=agent_id, mode='static')\n",
    "        print(f\"[Agentic] Agent {agent_id} output: {out.detach().cpu().numpy()}\")\n",
    "\n",
    "print(\"\\n[Agentic][Static Routing] Agent outputs BEFORE:\")\n",
    "print_agent_outputs(model, X, n_agents)\n",
    "\n",
    "# Use real AG News samples for fine-tuning agent 0\n",
    "# target_agent = 0  # Or another agent index\n",
    "# X_new = X[:20]\n",
    "# user_ids_new = torch.ones(20, dtype=torch.long) * target_agent\n",
    "# y_new = y[:20]\n",
    "\n",
    "target_agent = 0\n",
    "idxs = (y == target_agent).nonzero(as_tuple=True)[0]\n",
    "X_new = X[idxs]\n",
    "y_new = y[idxs]\n",
    "\n",
    "optimizer = torch.optim.Adam(model.dual_routing_module.agents[target_agent].parameters(), lr=5e-4)\n",
    "\n",
    "print(\"\\n[Agentic][Static Routing][Training] Agent 0 fine-tuning ...\")\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    for i in range(len(X_new)):\n",
    "        # Static routing: always assign to agent 0\n",
    "        out = model(X_new[i].unsqueeze(0), user_id=target_agent, mode='static')\n",
    "        loss = clf_loss_fn(out, y_new[i].unsqueeze(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[Agentic][Static Routing][Agent {target_agent} Fine-Tuning] Epoch {epoch+1} | Loss: {total_loss:.3f}\")\n",
    "\n",
    "print(\"\\n[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:\")\n",
    "print_agent_outputs(model, X, n_agents)\n",
    "\n",
    "def evaluate_per_agent_static_routing(model, X, y, n_agents):\n",
    "    results = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for agent_id in range(n_agents):\n",
    "            idxs = (y == agent_id).nonzero(as_tuple=True)[0]\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in idxs:\n",
    "                out = model(X[i].unsqueeze(0), user_id=agent_id, mode='static')\n",
    "                pred = out.argmax(dim=1).item()\n",
    "                correct += (pred == y[i].item())\n",
    "                total += 1\n",
    "            acc = correct / total if total > 0 else 0\n",
    "            results.append(acc)\n",
    "    return results\n",
    "\n",
    "# For static routing, each sample is assigned to its label as agent\n",
    "handled_by_static = [label.item() for label in y]\n",
    "per_agent_acc_static = evaluate_per_agent_handled(model, X, y, handled_by_static, n_agents, mode='static')\n",
    "print(\"[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples):\", per_agent_acc_static)\n",
    "\n",
    "# --------- 7. CAC Scenario: Multi-agent Coordination Modes ---------\n",
    "\n",
    "# (A) Parallel aggregation (default)\n",
    "\n",
    "# Majority Voting aggregation\n",
    "def majority_vote(outputs):\n",
    "    preds = [out.argmax(dim=-1).item() for out in outputs]\n",
    "    # In case of ties, returns the smallest class\n",
    "    return max(set(preds), key=preds.count)\n",
    "\n",
    "# Softmax Mean aggregation\n",
    "def softmax_mean(outputs):\n",
    "    probs = [F.softmax(out, dim=-1) for out in outputs]\n",
    "    mean_probs = torch.mean(torch.stack(probs, dim=0), dim=0)\n",
    "    return mean_probs.argmax(dim=-1).item()\n",
    "    \n",
    "cac_parallel = CAC(model)\n",
    "\n",
    "input_example = X[2].unsqueeze(0)\n",
    "agents_to_coord = [0, 1, 2, 3]\n",
    "\n",
    "print(\"\\n[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):\")\n",
    "\n",
    "# Get each agent's output\n",
    "agent_outputs_A = []\n",
    "for aid in agents_to_coord:\n",
    "    out = model(input_example, user_id=aid, mode='static')\n",
    "    agent_outputs_A.append(out)\n",
    "    print(f\"[Agentic][CAC] Individual Agent {aid} output: {out.detach()}\")\n",
    "\n",
    "# # Majority voting aggregation\n",
    "# maj_vote_pred = majority_vote(agent_outputs_A)\n",
    "# print(f\"Majority Vote predicted class: {maj_vote_pred}\")\n",
    "\n",
    "# # Softmax mean aggregation\n",
    "# softmax_mean_pred = softmax_mean(agent_outputs_A)\n",
    "# print(f\"Softmax Mean predicted class: {softmax_mean_pred}\")\n",
    "\n",
    "# # For comparison: mean aggregation (as before)\n",
    "# mean_output = torch.mean(torch.stack(aagent_outputs_A, dim=0), dim=0)\n",
    "# mean_pred = mean_output.argmax(dim=-1).item()\n",
    "# print(f\"Mean (raw logits) predicted class: {mean_pred}\")\n",
    "\n",
    "agent_outputs_A = torch.cat(agent_outputs_A, dim=0)  # shape: [4, 1, num_classes]\n",
    "# Aggregate (mean or softmax/majority vote as before)\n",
    "mean_output_A = agent_outputs_A.mean(dim=0)  # shape: [num_classes]\n",
    "print(\"[Agentic][CAC] Mean (raw logits) predicted class:\", mean_output_A.argmax(dim=0).item())\n",
    "\n",
    "# (B) Learnable coordinator (random selection for illustration)\n",
    "# Freeze backbone and agents\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "for agent in model.dual_routing_module.agents:\n",
    "    for param in agent.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define coordinator (to be trained)\n",
    "model_dim = 32\n",
    "n_agents = 4\n",
    "coordinator = LearnableCoordinator(model_dim, n_agents, n_select=2)\n",
    "cac = CAC(model, coordinator=coordinator)\n",
    "\n",
    "# Example batch\n",
    "# batch_X = X[:8]  # Batch of 8 samples\n",
    "agent_ids = list(range(n_agents))\n",
    "\n",
    "# Forward pass (agent selection is dynamic, learned)\n",
    "print(\"\\n[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:\")\n",
    "agent_outputs_B = cac.forward(input_example, agent_ids=agent_ids, mode='static')\n",
    "print(f\"[Agentic][CAC] Aggregated output (learnable selection): {agent_outputs_B.detach()}\")\n",
    "\n",
    "# To see which agents were picked:\n",
    "with torch.no_grad():\n",
    "    features = model.backbone(input_example)\n",
    "    selected_agents = coordinator(features, agent_ids)[0]\n",
    "    print(\"[Agentic] Agents selected by coordinator:\", selected_agents)\n",
    "    for aid in selected_agents:\n",
    "        out = model(input_example, user_id=aid, mode='static')\n",
    "        print(f\"[Agentic][CAC] Selected Agent {aid} output: {out.detach()}\")\n",
    "\n",
    "mean_output_B = agent_outputs_B.mean(dim=0)  # shape: [num_classes]\n",
    "pred_class = mean_output_B.argmax().item()\n",
    "print(\"[Agentic][CAC] Mean (raw logits) predicted class:\", pred_class)\n",
    "\n",
    "# (C) Workflow-based coordinator (sequential handoff)\n",
    "# workflow = [0, 2]\n",
    "# cac_workflow = CAC(model, workflow=workflow)\n",
    "\n",
    "# print(\"\\n[Workflow Coordinator] Sequential workflow for input X[2]:\")\n",
    "# workflow_output = cac_workflow.forward(input_example, agent_ids=list(range(n_agents)), mode='static')\n",
    "# print(f\"Workflow output (final agent): {workflow_output.detach()}\")\n",
    "\n",
    "# (D) Task decomposition and routing (example usage of decompose_and_route)\n",
    "# sample_idx = 10\n",
    "# article = dataset[sample_idx]\n",
    "# print(\"\\n[Decompose and Route]:\")    \n",
    "# subtasks, routed_agents = cac_parallel.decompose_and_route(article, agents=[0,1,2,3], vocab=vocab)\n",
    "# for subtask, aid in zip(subtasks, routed_agents):\n",
    "#     out = model(subtask, user_id=aid, mode='static')\n",
    "#     print(f\"Agent {aid} processed: {out.detach().cpu().numpy()}\")\n",
    "\n",
    "# # Optionally, aggregate the outputs (e.g., mean or majority vote)\n",
    "# outputs = [model(subtask, user_id=aid, mode='static') for subtask, aid in zip(subtasks, routed_agents)]\n",
    "# agg_output = torch.mean(torch.stack(outputs, dim=0), dim=0)\n",
    "# print(f\"Aggregated output (headline+body): {agg_output.detach()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b60767-49d4-4676-8872-66b9e7efa7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crewai_env)",
   "language": "python",
   "name": "crewai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
