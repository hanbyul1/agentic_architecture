{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2374ba-b944-48b0-84fe-37f15210ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoE][Training] Epoch 1 | CE: 0.989 | LB: 0.008 | Router: 0.987 | Entropy: 0.992\n",
      "[MoE][Training] Hard assignment counts per expert: [30400, 32616, 26932, 30052]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24954630434513092, 0.2502956688404083, 0.2502772808074951, 0.24988067150115967]\n",
      "[MoE][Training] Epoch 2 | CE: 0.620 | LB: 0.014 | Router: 0.618 | Entropy: 0.619\n",
      "[MoE][Training] Hard assignment counts per expert: [29096, 32075, 28704, 30125]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24949970841407776, 0.25036853551864624, 0.25016531348228455, 0.2499663382768631]\n",
      "[MoE][Training] Epoch 3 | CE: 0.484 | LB: 0.016 | Router: 0.483 | Entropy: 0.481\n",
      "[MoE][Training] Hard assignment counts per expert: [29009, 31442, 29247, 30302]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.2496137171983719, 0.25029751658439636, 0.250068724155426, 0.25002002716064453]\n",
      "[MoE][Training] Epoch 4 | CE: 0.402 | LB: 0.017 | Router: 0.400 | Entropy: 0.398\n",
      "[MoE][Training] Hard assignment counts per expert: [29023, 31066, 29442, 30469]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24964575469493866, 0.25025540590286255, 0.24982775747776031, 0.25027114152908325]\n",
      "[MoE][Training] Epoch 5 | CE: 0.348 | LB: 0.018 | Router: 0.346 | Entropy: 0.344\n",
      "[MoE][Training] Hard assignment counts per expert: [28925, 30908, 29575, 30592]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24984818696975708, 0.24993392825126648, 0.25025519728660583, 0.2499617338180542]\n",
      "[MoE] Final routing distribution: {0: 2034, 1: 1901, 2: 1886, 3: 1779}\n",
      "[MoE][testing] Per-expert accuracy on test set: [0.858421052631579, 0.8810526315789474, 0.8005263157894736, 0.7873684210526316]\n",
      "\n",
      "[MoE] Confusion Matrix: Rows = True Class, Columns = Routed Expert\n",
      "tensor([[1627,   94,  111,   68],\n",
      "        [ 131, 1675,   52,   42],\n",
      "        [ 149,   57, 1522,  172],\n",
      "        [ 127,   75,  201, 1497]])\n",
      "[MoE][testing] Overall test accuracy: 0.8318421052631579\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- 1. Load AG News data: train and test splits ---\n",
    "train_dataset = load_dataset('ag_news', split='train')\n",
    "test_dataset  = load_dataset('ag_news', split='test')\n",
    "\n",
    "# --- 2. Build vocabulary using ONLY training data ---\n",
    "tokenizer = lambda s: s.lower().split()\n",
    "vocab = build_vocab_from_iterator((tokenizer(x['text']) for x in train_dataset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# --- 3. Encode samples for train and test separately ---\n",
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return torch.tensor([vocab[token] for token in tokens][:8])  # seq_len=8\n",
    "\n",
    "X_train = [encode(sample['text']) for sample in train_dataset]\n",
    "X_train = pad_sequence(X_train, batch_first=True, padding_value=0)\n",
    "y_train = torch.tensor([sample['label'] for sample in train_dataset])\n",
    "\n",
    "X_test = [encode(sample['text']) for sample in test_dataset]\n",
    "X_test = pad_sequence(X_test, batch_first=True, padding_value=0)\n",
    "y_test = torch.tensor([sample['label'] for sample in test_dataset])\n",
    "\n",
    "n_samples_train = len(X_train)\n",
    "n_samples_test = len(X_test)\n",
    "\n",
    "# --- 4. Model Definitions ---\n",
    "class RoutingNetwork(nn.Module):\n",
    "    def __init__(self, model_dim, n_experts):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(model_dim, n_experts)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # (batch, n_experts)\n",
    "\n",
    "class MoEBackbone(nn.Module):\n",
    "    def __init__(self, vocab_size, model_dim, n_heads=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 10, model_dim))  # Max seq len 10\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=n_heads, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_embedding[:, :x.size(1)]\n",
    "        out = self.encoder(x)\n",
    "        return out[:, 0, :]  # Use the first token as representation\n",
    "\n",
    "class MoEExpert(nn.Module):\n",
    "    def __init__(self, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, n_experts, vocab_size, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = MoEBackbone(vocab_size, model_dim, n_heads=2)\n",
    "        self.experts = nn.ModuleList([MoEExpert(model_dim, out_dim) for _ in range(n_experts)])\n",
    "        self.router = RoutingNetwork(model_dim, n_experts)\n",
    "\n",
    "    def forward(self, x, return_probs=False):\n",
    "        shared = self.backbone(x)  # (batch, model_dim)\n",
    "        expert_logits = self.router(shared)  # (batch, n_experts)\n",
    "        expert_probs = torch.softmax(expert_logits, dim=-1)\n",
    "        expert_idx = torch.argmax(expert_probs, dim=-1)\n",
    "        if shared.size(0) == 1:\n",
    "            idx = expert_idx.item() if isinstance(expert_idx, torch.Tensor) else expert_idx\n",
    "            out = self.experts[idx](shared)\n",
    "        else:\n",
    "            outs = []\n",
    "            for i in range(shared.size(0)):\n",
    "                idx = expert_idx[i].item() if isinstance(expert_idx, torch.Tensor) else expert_idx[i]\n",
    "                outs.append(self.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "        if return_probs:\n",
    "            return out, expert_probs\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# --- 5. Training/Evaluation Utilities (updated for train/test split) ---\n",
    "\n",
    "def train_joint_moe_supervised_router(\n",
    "    model, X, y, loss_fn, optimizer, epochs=5, n_experts=4,\n",
    "    lb_lambda=3, router_lambda=1.0, entropy_lambda=0.05, batch_size=32\n",
    "):\n",
    "    n_samples = len(X)\n",
    "    indices = torch.arange(n_samples)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_lb_loss = 0\n",
    "        total_router_loss = 0\n",
    "        total_entropy = 0\n",
    "        model.train()\n",
    "        routing_counts = [0 for _ in range(n_experts)]\n",
    "        expert_probs_sum = torch.zeros(n_experts)\n",
    "\n",
    "        indices = indices[torch.randperm(n_samples)]\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            batch_idx = indices[batch_start:batch_start+batch_size]\n",
    "            X_batch = X[batch_idx]\n",
    "            y_batch = y[batch_idx]\n",
    "            \n",
    "            shared = model.backbone(X_batch)\n",
    "            router_logits = model.router(shared)  # (batch, n_experts)\n",
    "            expert_probs = torch.softmax(router_logits, dim=-1)\n",
    "            hard_assign = expert_probs.argmax(dim=-1)\n",
    "            for k in range(n_experts):\n",
    "                routing_counts[k] += (hard_assign == k).sum().item()\n",
    "            expert_probs_sum += expert_probs.sum(dim=0).detach()\n",
    "\n",
    "            # Supervised router loss\n",
    "            router_loss = nn.CrossEntropyLoss()(router_logits, y_batch)\n",
    "            \n",
    "            # Main MoE output (with dynamic routing)\n",
    "            expert_idx = hard_assign\n",
    "            outs = []\n",
    "            for i in range(X_batch.size(0)):\n",
    "                idx = expert_idx[i].item()\n",
    "                outs.append(model.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "\n",
    "            ce_loss = loss_fn(out, y_batch)\n",
    "            probs_mean = expert_probs.mean(dim=0)\n",
    "            lb_loss = ((probs_mean - 1.0/n_experts) ** 2).sum()\n",
    "            \n",
    "            # Entropy regularization (maximize entropy for diversity)\n",
    "            entropy = -torch.sum(expert_probs * torch.log(expert_probs + 1e-8), dim=1).mean()\n",
    "\n",
    "            # Total loss\n",
    "            loss = ce_loss + lb_lambda * lb_loss + router_lambda * router_loss + entropy_lambda * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += ce_loss.item() * X_batch.size(0)\n",
    "            total_lb_loss += lb_loss.item() * X_batch.size(0)\n",
    "            total_router_loss += router_loss.item() * X_batch.size(0)\n",
    "            total_entropy += entropy.item() * X_batch.size(0)\n",
    "\n",
    "        print(f\"[MoE][Training] Epoch {epoch+1} | CE: {total_loss/n_samples_train:.3f} | LB: {total_lb_loss/n_samples_train:.3f} | Router: {total_router_loss/n_samples_train:.3f} | Entropy: {total_entropy/n_samples_train:.3f}\")\n",
    "        print(\"[MoE][Training] Hard assignment counts per expert:\", routing_counts)\n",
    "        print(\"[MoE][Training] Mean softmax probability per expert:\", (expert_probs_sum / n_samples_train).tolist())\n",
    "\n",
    "def evaluate_per_expert_moe(model, X, y, n_experts, batch_size=32):\n",
    "    results = []\n",
    "    model.eval()\n",
    "    expert_assignments = []\n",
    "    n_samples = len(X)\n",
    "    with torch.no_grad():\n",
    "        for expert_id in range(n_experts):\n",
    "            idxs = (y == expert_id).nonzero(as_tuple=True)[0]\n",
    "            if len(idxs) == 0:\n",
    "                results.append(float('nan'))\n",
    "                continue\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_start in range(0, len(idxs), batch_size):\n",
    "                batch_idx = idxs[batch_start:batch_start+batch_size]\n",
    "                X_batch = X[batch_idx]\n",
    "                y_batch = y[batch_idx]\n",
    "                out, expert_probs = model(X_batch, True)\n",
    "                pred = out.argmax(dim=1)\n",
    "                routed_expert = expert_probs.argmax(dim=-1)\n",
    "                expert_assignments += routed_expert.cpu().tolist()\n",
    "                correct += (pred == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "            acc = correct / total if total > 0 else 0\n",
    "            results.append(acc)\n",
    "    # Print final routing histogram for analysis\n",
    "    unique, counts = torch.tensor(expert_assignments).unique(return_counts=True)\n",
    "    dist = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "    print(f\"[MoE] Final routing distribution: {dist}\")\n",
    "    return results\n",
    "\n",
    "# --- 6. Confusion Matrix Utility ---\n",
    "def compute_routing_confusion(model, X, y, n_experts, n_classes=4, batch_size=32):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "    except ImportError:\n",
    "        confusion_matrix = None\n",
    "    confusion = torch.zeros(n_classes, n_experts, dtype=torch.long)\n",
    "    n_samples = len(X)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1)\n",
    "            for i in range(X_batch.size(0)):\n",
    "                true_label = y_batch[i].item()\n",
    "                expert = routed_expert[i].item()\n",
    "                confusion[true_label, expert] += 1\n",
    "    print(\"\\n[MoE] Confusion Matrix: Rows = True Class, Columns = Routed Expert\")\n",
    "    print(confusion)\n",
    "    if confusion_matrix is not None:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1).cpu().tolist()\n",
    "            y_true.extend(y_batch.cpu().tolist())\n",
    "            y_pred.extend(routed_expert)\n",
    "        print(\"\\n[MoE] Sklearn confusion_matrix (same axes):\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# --- 7. Usage Example: Only train on train set, evaluate on test set ---\n",
    "n_experts = 4\n",
    "model_dim = 32\n",
    "out_dim = 4\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "moe_model = MoE(n_experts, vocab_size, model_dim, out_dim)\n",
    "moe_loss_fn = nn.CrossEntropyLoss()\n",
    "moe_optimizer = optim.Adam(moe_model.parameters(), lr=1e-3)\n",
    "epochs = 5\n",
    "\n",
    "# TRAINING (on training set only)\n",
    "train_joint_moe_supervised_router(\n",
    "    moe_model, X_train, y_train, moe_loss_fn, moe_optimizer,\n",
    "    epochs=epochs, n_experts=n_experts, lb_lambda=3, router_lambda=1.0, batch_size=32\n",
    ")\n",
    "\n",
    "# TESTING (on test set only)\n",
    "moe_acc = evaluate_per_expert_moe(moe_model, X_test, y_test, n_experts)\n",
    "print(\"[MoE][testing] Per-expert accuracy on test set:\", moe_acc)\n",
    "\n",
    "# Confusion Matrix (test set)\n",
    "compute_routing_confusion(moe_model, X_test, y_test, n_experts, n_classes=4, batch_size=32)\n",
    "\n",
    "# Overall test accuracy\n",
    "def compute_overall_accuracy(model, X, y, batch_size=32):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, len(X), batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            out = model(X_batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return correct / total\n",
    "\n",
    "test_acc = compute_overall_accuracy(moe_model, X_test, y_test)\n",
    "print(\"[MoE][testing] Overall test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebebe47-fa3e-4d46-8002-4794cf8dacaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crewai_env)",
   "language": "python",
   "name": "crewai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
