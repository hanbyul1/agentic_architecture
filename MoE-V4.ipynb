{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2374ba-b944-48b0-84fe-37f15210ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoE][Training] Epoch 1 | CE: 1.339 | LB: 0.011 | Router: 1.359 | Entropy: 1.347\n",
      "[MoE][Training] Hard assignment counts per expert: [350, 157, 340, 1153]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.23927611112594604, 0.21953769028186798, 0.2361777424812317, 0.30500850081443787]\n",
      "[MoE][Training] Epoch 2 | CE: 1.275 | LB: 0.008 | Router: 1.265 | Entropy: 1.315\n",
      "[MoE][Training] Hard assignment counts per expert: [395, 84, 460, 1061]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24693386256694794, 0.21645745635032654, 0.23176109790802002, 0.3048475384712219]\n",
      "[MoE][Training] Epoch 3 | CE: 1.166 | LB: 0.011 | Router: 1.139 | Entropy: 1.197\n",
      "[MoE][Training] Hard assignment counts per expert: [504, 271, 437, 788]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.2517864406108856, 0.21816454827785492, 0.22556084394454956, 0.3044881820678711]\n",
      "[MoE][Training] Epoch 4 | CE: 1.043 | LB: 0.017 | Router: 1.026 | Entropy: 1.095\n",
      "[MoE][Training] Hard assignment counts per expert: [478, 332, 441, 749]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24436601996421814, 0.21985971927642822, 0.22642134130001068, 0.3093528747558594]\n",
      "[MoE][Training] Epoch 5 | CE: 0.843 | LB: 0.016 | Router: 0.839 | Entropy: 0.974\n",
      "[MoE][Training] Hard assignment counts per expert: [470, 380, 436, 714]\n",
      "[MoE][Training] Mean softmax probability per expert: [0.24619005620479584, 0.21748550236225128, 0.22143103182315826, 0.31489333510398865]\n",
      "[MoE] Final routing distribution: {0: 465, 1: 323, 2: 506, 3: 706}\n",
      "[MoE][testing] Per-expert accuracy after joint training: [0.750524109014675, 0.6242603550295858, 0.8823529411764706, 0.7953667953667953]\n",
      "\n",
      "[MoE] Confusion Matrix: Rows = True Class, Columns = Routed Expert\n",
      "tensor([[360,  29,  54,  34],\n",
      "        [ 49, 221,  22,  46],\n",
      "        [ 16,   9, 360,  23],\n",
      "        [ 40,  64,  70, 603]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# --- 1. Load AG News data ---\n",
    "dataset = load_dataset('ag_news', split='train[:2000]')\n",
    "\n",
    "# --- 2. Build vocabulary ---\n",
    "tokenizer = lambda s: s.lower().split()\n",
    "vocab = build_vocab_from_iterator((tokenizer(x['text']) for x in dataset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# --- 3. Encode samples ---\n",
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return torch.tensor([vocab[token] for token in tokens][:8])  # seq_len=8\n",
    "\n",
    "X = [encode(sample['text']) for sample in dataset]\n",
    "X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "y = torch.tensor([sample['label'] for sample in dataset])\n",
    "\n",
    "# --- 4. Model Definitions ---\n",
    "class RoutingNetwork(nn.Module):\n",
    "    def __init__(self, model_dim, n_experts):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(model_dim, n_experts)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # (batch, n_experts)\n",
    "\n",
    "class MoEBackbone(nn.Module):\n",
    "    def __init__(self, vocab_size, model_dim, n_heads=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 10, model_dim))  # Max seq len 10\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=n_heads, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_embedding[:, :x.size(1)]\n",
    "        out = self.encoder(x)\n",
    "        return out[:, 0, :]  # Use the first token as representation\n",
    "\n",
    "class MoEExpert(nn.Module):\n",
    "    def __init__(self, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, n_experts, vocab_size, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = MoEBackbone(vocab_size, model_dim, n_heads=2)\n",
    "        self.experts = nn.ModuleList([MoEExpert(model_dim, out_dim) for _ in range(n_experts)])\n",
    "        self.router = RoutingNetwork(model_dim, n_experts)\n",
    "\n",
    "    def forward(self, x, return_probs=False):\n",
    "        shared = self.backbone(x)  # (batch, model_dim)\n",
    "        expert_logits = self.router(shared)  # (batch, n_experts)\n",
    "        expert_probs = torch.softmax(expert_logits, dim=-1)\n",
    "        expert_idx = torch.argmax(expert_probs, dim=-1)\n",
    "        if shared.size(0) == 1:\n",
    "            idx = expert_idx.item() if isinstance(expert_idx, torch.Tensor) else expert_idx\n",
    "            out = self.experts[idx](shared)\n",
    "        else:\n",
    "            outs = []\n",
    "            for i in range(shared.size(0)):\n",
    "                idx = expert_idx[i].item() if isinstance(expert_idx, torch.Tensor) else expert_idx[i]\n",
    "                outs.append(self.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "        if return_probs:\n",
    "            return out, expert_probs\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# --- 5. Training/Evaluation Utilities ---\n",
    "\n",
    "def train_joint_moe_supervised_router(\n",
    "    model, X, y, loss_fn, optimizer, epochs=5, n_experts=4,\n",
    "    lb_lambda=3, router_lambda=1.0, entropy_lambda=0.05, batch_size=32\n",
    "):\n",
    "    n_samples = len(X)\n",
    "    indices = torch.arange(n_samples)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_lb_loss = 0\n",
    "        total_router_loss = 0\n",
    "        total_entropy = 0\n",
    "        model.train()\n",
    "        routing_counts = [0 for _ in range(n_experts)]\n",
    "        expert_probs_sum = torch.zeros(n_experts)\n",
    "\n",
    "        indices = indices[torch.randperm(n_samples)]\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            batch_idx = indices[batch_start:batch_start+batch_size]\n",
    "            X_batch = X[batch_idx]\n",
    "            y_batch = y[batch_idx]\n",
    "            \n",
    "            shared = model.backbone(X_batch)\n",
    "            router_logits = model.router(shared)  # (batch, n_experts)\n",
    "            expert_probs = torch.softmax(router_logits, dim=-1)\n",
    "            hard_assign = expert_probs.argmax(dim=-1)\n",
    "            for k in range(n_experts):\n",
    "                routing_counts[k] += (hard_assign == k).sum().item()\n",
    "            expert_probs_sum += expert_probs.sum(dim=0).detach()\n",
    "\n",
    "            # Supervised router loss\n",
    "            router_loss = nn.CrossEntropyLoss()(router_logits, y_batch)\n",
    "            \n",
    "            # Main MoE output (with dynamic routing)\n",
    "            expert_idx = hard_assign\n",
    "            outs = []\n",
    "            for i in range(X_batch.size(0)):\n",
    "                idx = expert_idx[i].item()\n",
    "                outs.append(model.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "\n",
    "            ce_loss = loss_fn(out, y_batch)\n",
    "            probs_mean = expert_probs.mean(dim=0)\n",
    "            lb_loss = ((probs_mean - 1.0/n_experts) ** 2).sum()\n",
    "            \n",
    "            # Entropy regularization (maximize entropy for diversity)\n",
    "            entropy = -torch.sum(expert_probs * torch.log(expert_probs + 1e-8), dim=1).mean()\n",
    "\n",
    "            # Total loss\n",
    "            loss = ce_loss + lb_lambda * lb_loss + router_lambda * router_loss + entropy_lambda * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += ce_loss.item() * X_batch.size(0)\n",
    "            total_lb_loss += lb_loss.item() * X_batch.size(0)\n",
    "            total_router_loss += router_loss.item() * X_batch.size(0)\n",
    "            total_entropy += entropy.item() * X_batch.size(0)\n",
    "\n",
    "        print(f\"[MoE][Training] Epoch {epoch+1} | CE: {total_loss/n_samples:.3f} | LB: {total_lb_loss/n_samples:.3f} | Router: {total_router_loss/n_samples:.3f} | Entropy: {total_entropy/n_samples:.3f}\")\n",
    "        print(\"[MoE][Training] Hard assignment counts per expert:\", routing_counts)\n",
    "        print(\"[MoE][Training] Mean softmax probability per expert:\", (expert_probs_sum / n_samples).tolist())\n",
    "\n",
    "\n",
    "def evaluate_per_expert_moe(model, X, y, n_experts, batch_size=32):\n",
    "    results = []\n",
    "    model.eval()\n",
    "    expert_assignments = []\n",
    "    n_samples = len(X)\n",
    "    with torch.no_grad():\n",
    "        for expert_id in range(n_experts):\n",
    "            idxs = (y == expert_id).nonzero(as_tuple=True)[0]\n",
    "            if len(idxs) == 0:\n",
    "                results.append(float('nan'))\n",
    "                continue\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_start in range(0, len(idxs), batch_size):\n",
    "                batch_idx = idxs[batch_start:batch_start+batch_size]\n",
    "                X_batch = X[batch_idx]\n",
    "                y_batch = y[batch_idx]\n",
    "                out, expert_probs = model(X_batch, True)\n",
    "                pred = out.argmax(dim=1)\n",
    "                routed_expert = expert_probs.argmax(dim=-1)\n",
    "                expert_assignments += routed_expert.cpu().tolist()\n",
    "                correct += (pred == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "            acc = correct / total if total > 0 else 0\n",
    "            results.append(acc)\n",
    "    # Print final routing histogram for analysis\n",
    "    unique, counts = torch.tensor(expert_assignments).unique(return_counts=True)\n",
    "    dist = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "    print(f\"[MoE] Final routing distribution: {dist}\")\n",
    "    return results\n",
    "\n",
    "# --- 6. Confusion Matrix Utility ---\n",
    "def compute_routing_confusion(model, X, y, n_experts, n_classes=4, batch_size=32):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "    except ImportError:\n",
    "        confusion_matrix = None\n",
    "    # true_class x routed_expert\n",
    "    confusion = torch.zeros(n_classes, n_experts, dtype=torch.long)\n",
    "    n_samples = len(X)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1)  # (batch,)\n",
    "            for i in range(X_batch.size(0)):\n",
    "                true_label = y_batch[i].item()\n",
    "                expert = routed_expert[i].item()\n",
    "                confusion[true_label, expert] += 1\n",
    "    print(\"\\n[MoE] Confusion Matrix: Rows = True Class, Columns = Routed Expert\")\n",
    "    print(confusion)\n",
    "    # If sklearn is available, print as well:\n",
    "    if confusion_matrix is not None:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1).cpu().tolist()\n",
    "            y_true.extend(y_batch.cpu().tolist())\n",
    "            y_pred.extend(routed_expert)\n",
    "        print(\"\\n[MoE] Sklearn confusion_matrix (same axes):\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# --- 7. Usage Example ---\n",
    "\n",
    "n_experts = 4\n",
    "model_dim = 32\n",
    "out_dim = 4\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "moe_model = MoE(n_experts, vocab_size, model_dim, out_dim)\n",
    "moe_loss_fn = nn.CrossEntropyLoss()\n",
    "moe_optimizer = optim.Adam(moe_model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "train_joint_moe_supervised_router(moe_model, X, y, moe_loss_fn, moe_optimizer, epochs=epochs, n_experts=n_experts, lb_lambda=3, router_lambda=1.0, batch_size=32)\n",
    "\n",
    "moe_acc = evaluate_per_expert_moe(moe_model, X, y, n_experts)\n",
    "print(\"[MoE][testing] Per-expert accuracy after joint training:\", moe_acc)\n",
    "\n",
    "# --- 8. Confusion Matrix (routing specialization) ---\n",
    "compute_routing_confusion(moe_model, X, y, n_experts, n_classes=4, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebebe47-fa3e-4d46-8002-4794cf8dacaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crewai_env)",
   "language": "python",
   "name": "crewai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
