{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2374ba-b944-48b0-84fe-37f15210ec37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequence\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mrandom\u001b[49m.seed(\u001b[32m42\u001b[39m)\n\u001b[32m     12\u001b[39m np.random.seed(\u001b[32m42\u001b[39m)\n\u001b[32m     13\u001b[39m torch.manual_seed(\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# --- 1. Load AG News data ---\n",
    "dataset = load_dataset('ag_news', split='train[:2000]')\n",
    "\n",
    "# --- 2. Build vocabulary ---\n",
    "tokenizer = lambda s: s.lower().split()\n",
    "vocab = build_vocab_from_iterator((tokenizer(x['text']) for x in dataset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# --- 3. Encode samples ---\n",
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return torch.tensor([vocab[token] for token in tokens][:8])  # seq_len=8\n",
    "\n",
    "X = [encode(sample['text']) for sample in dataset]\n",
    "X = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "y = torch.tensor([sample['label'] for sample in dataset])\n",
    "\n",
    "# --- 4. Model Definitions ---\n",
    "class RoutingNetwork(nn.Module):\n",
    "    def __init__(self, model_dim, n_experts):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(model_dim, n_experts)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)  # (batch, n_experts)\n",
    "\n",
    "class MoEBackbone(nn.Module):\n",
    "    def __init__(self, vocab_size, model_dim, n_heads=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 10, model_dim))  # Max seq len 10\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=n_heads, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.pos_embedding[:, :x.size(1)]\n",
    "        out = self.encoder(x)\n",
    "        return out[:, 0, :]  # Use the first token as representation\n",
    "\n",
    "class MoEExpert(nn.Module):\n",
    "    def __init__(self, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(model_dim, model_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, n_experts, vocab_size, model_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = MoEBackbone(vocab_size, model_dim, n_heads=2)\n",
    "        self.experts = nn.ModuleList([MoEExpert(model_dim, out_dim) for _ in range(n_experts)])\n",
    "        self.router = RoutingNetwork(model_dim, n_experts)\n",
    "\n",
    "    def forward(self, x, return_probs=False):\n",
    "        shared = self.backbone(x)  # (batch, model_dim)\n",
    "        expert_logits = self.router(shared)  # (batch, n_experts)\n",
    "        expert_probs = torch.softmax(expert_logits, dim=-1)\n",
    "        expert_idx = torch.argmax(expert_probs, dim=-1)\n",
    "        if shared.size(0) == 1:\n",
    "            idx = expert_idx.item() if isinstance(expert_idx, torch.Tensor) else expert_idx\n",
    "            out = self.experts[idx](shared)\n",
    "        else:\n",
    "            outs = []\n",
    "            for i in range(shared.size(0)):\n",
    "                idx = expert_idx[i].item() if isinstance(expert_idx, torch.Tensor) else expert_idx[i]\n",
    "                outs.append(self.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "        if return_probs:\n",
    "            return out, expert_probs\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "# --- 5. Training/Evaluation Utilities ---\n",
    "\n",
    "def train_joint_moe_supervised_router(\n",
    "    model, X, y, loss_fn, optimizer, epochs=5, n_experts=4,\n",
    "    lb_lambda=3, router_lambda=1.0, entropy_lambda=0.05, batch_size=32\n",
    "):\n",
    "    n_samples = len(X)\n",
    "    indices = torch.arange(n_samples)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_lb_loss = 0\n",
    "        total_router_loss = 0\n",
    "        total_entropy = 0\n",
    "        model.train()\n",
    "        routing_counts = [0 for _ in range(n_experts)]\n",
    "        expert_probs_sum = torch.zeros(n_experts)\n",
    "\n",
    "        indices = indices[torch.randperm(n_samples)]\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            batch_idx = indices[batch_start:batch_start+batch_size]\n",
    "            X_batch = X[batch_idx]\n",
    "            y_batch = y[batch_idx]\n",
    "            \n",
    "            shared = model.backbone(X_batch)\n",
    "            router_logits = model.router(shared)  # (batch, n_experts)\n",
    "            expert_probs = torch.softmax(router_logits, dim=-1)\n",
    "            hard_assign = expert_probs.argmax(dim=-1)\n",
    "            for k in range(n_experts):\n",
    "                routing_counts[k] += (hard_assign == k).sum().item()\n",
    "            expert_probs_sum += expert_probs.sum(dim=0).detach()\n",
    "\n",
    "            # Supervised router loss\n",
    "            router_loss = nn.CrossEntropyLoss()(router_logits, y_batch)\n",
    "            \n",
    "            # Main MoE output (with dynamic routing)\n",
    "            expert_idx = hard_assign\n",
    "            outs = []\n",
    "            for i in range(X_batch.size(0)):\n",
    "                idx = expert_idx[i].item()\n",
    "                outs.append(model.experts[idx](shared[i:i+1]))\n",
    "            out = torch.cat(outs, dim=0)\n",
    "\n",
    "            ce_loss = loss_fn(out, y_batch)\n",
    "            probs_mean = expert_probs.mean(dim=0)\n",
    "            lb_loss = ((probs_mean - 1.0/n_experts) ** 2).sum()\n",
    "            \n",
    "            # Entropy regularization (maximize entropy for diversity)\n",
    "            entropy = -torch.sum(expert_probs * torch.log(expert_probs + 1e-8), dim=1).mean()\n",
    "\n",
    "            # Total loss\n",
    "            loss = ce_loss + lb_lambda * lb_loss + router_lambda * router_loss + entropy_lambda * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += ce_loss.item() * X_batch.size(0)\n",
    "            total_lb_loss += lb_loss.item() * X_batch.size(0)\n",
    "            total_router_loss += router_loss.item() * X_batch.size(0)\n",
    "            total_entropy += entropy.item() * X_batch.size(0)\n",
    "\n",
    "        print(f\"[MoE][Training] Epoch {epoch+1} | CE: {total_loss/n_samples:.3f} | LB: {total_lb_loss/n_samples:.3f} | Router: {total_router_loss/n_samples:.3f} | Entropy: {total_entropy/n_samples:.3f}\")\n",
    "        print(\"[MoE][Training] Hard assignment counts per expert:\", routing_counts)\n",
    "        print(\"[MoE][Training] Mean softmax probability per expert:\", (expert_probs_sum / n_samples).tolist())\n",
    "\n",
    "\n",
    "def evaluate_per_expert_moe(model, X, y, n_experts, batch_size=32):\n",
    "    results = []\n",
    "    model.eval()\n",
    "    expert_assignments = []\n",
    "    n_samples = len(X)\n",
    "    with torch.no_grad():\n",
    "        for expert_id in range(n_experts):\n",
    "            idxs = (y == expert_id).nonzero(as_tuple=True)[0]\n",
    "            if len(idxs) == 0:\n",
    "                results.append(float('nan'))\n",
    "                continue\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_start in range(0, len(idxs), batch_size):\n",
    "                batch_idx = idxs[batch_start:batch_start+batch_size]\n",
    "                X_batch = X[batch_idx]\n",
    "                y_batch = y[batch_idx]\n",
    "                out, expert_probs = model(X_batch, True)\n",
    "                pred = out.argmax(dim=1)\n",
    "                routed_expert = expert_probs.argmax(dim=-1)\n",
    "                expert_assignments += routed_expert.cpu().tolist()\n",
    "                correct += (pred == y_batch).sum().item()\n",
    "                total += y_batch.size(0)\n",
    "            acc = correct / total if total > 0 else 0\n",
    "            results.append(acc)\n",
    "    # Print final routing histogram for analysis\n",
    "    unique, counts = torch.tensor(expert_assignments).unique(return_counts=True)\n",
    "    dist = {int(u): int(c) for u, c in zip(unique, counts)}\n",
    "    print(f\"[MoE] Final routing distribution: {dist}\")\n",
    "    return results\n",
    "\n",
    "# --- 6. Confusion Matrix Utility ---\n",
    "def compute_routing_confusion(model, X, y, n_experts, n_classes=4, batch_size=32):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "    except ImportError:\n",
    "        confusion_matrix = None\n",
    "    # true_class x routed_expert\n",
    "    confusion = torch.zeros(n_classes, n_experts, dtype=torch.long)\n",
    "    n_samples = len(X)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1)  # (batch,)\n",
    "            for i in range(X_batch.size(0)):\n",
    "                true_label = y_batch[i].item()\n",
    "                expert = routed_expert[i].item()\n",
    "                confusion[true_label, expert] += 1\n",
    "    print(\"\\n[MoE] Confusion Matrix: Rows = True Class, Columns = Routed Expert\")\n",
    "    print(confusion)\n",
    "    # If sklearn is available, print as well:\n",
    "    if confusion_matrix is not None:\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            X_batch = X[batch_start:batch_start+batch_size]\n",
    "            y_batch = y[batch_start:batch_start+batch_size]\n",
    "            _, expert_probs = model(X_batch, True)\n",
    "            routed_expert = expert_probs.argmax(dim=-1).cpu().tolist()\n",
    "            y_true.extend(y_batch.cpu().tolist())\n",
    "            y_pred.extend(routed_expert)\n",
    "        print(\"\\n[MoE] Sklearn confusion_matrix (same axes):\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# --- 7. Usage Example ---\n",
    "\n",
    "n_experts = 4\n",
    "model_dim = 32\n",
    "out_dim = 4\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "moe_model = MoE(n_experts, vocab_size, model_dim, out_dim)\n",
    "moe_loss_fn = nn.CrossEntropyLoss()\n",
    "moe_optimizer = optim.Adam(moe_model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "train_joint_moe_supervised_router(moe_model, X, y, moe_loss_fn, moe_optimizer, epochs=epochs, n_experts=n_experts, lb_lambda=3, router_lambda=1.0, batch_size=32)\n",
    "\n",
    "moe_acc = evaluate_per_expert_moe(moe_model, X, y, n_experts)\n",
    "print(\"[MoE][testing] Per-expert accuracy after joint training:\", moe_acc)\n",
    "\n",
    "# --- 8. Confusion Matrix (routing specialization) ---\n",
    "compute_routing_confusion(moe_model, X, y, n_experts, n_classes=4, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebebe47-fa3e-4d46-8002-4794cf8dacaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crewai_env)",
   "language": "python",
   "name": "crewai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
