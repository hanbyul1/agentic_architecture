Round 1

[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.382 | LB: 0.057 | Router: 1.315 | Entropy: 1.273
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [658, 228, 481, 633]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.266698956489563, 0.21239353716373444, 0.21618160605430603, 0.3047258257865906]
[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.336 | LB: 0.013 | Router: 1.361 | Entropy: 1.356
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [584, 137, 313, 966]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24575825035572052, 0.2183082550764084, 0.2336236983537674, 0.3023097515106201]
[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.319 | LB: 0.013 | Router: 1.338 | Entropy: 1.352
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [534, 184, 403, 879]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24657601118087769, 0.2181861847639084, 0.23389188945293427, 0.3013460040092468]
[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.271 | LB: 0.014 | Router: 1.273 | Entropy: 1.323
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [484, 259, 471, 786]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.25298845767974854, 0.218100905418396, 0.22845685482025146, 0.300453782081604]
[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.205 | LB: 0.018 | Router: 1.172 | Entropy: 1.237
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [488, 365, 503, 644]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.251554012298584, 0.22057770192623138, 0.22827701270580292, 0.2995913028717041]

[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent
tensor([[290,  78,  59,  50],
[ 27, 231,  54,  26],
[ 16,  60, 313,  19],
[108, 274, 128, 267]])
[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.6575963718820862, 0.37636080870917576, 0.5649819494584838, 0.7375690607734806]
[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 441, 1: 643, 2: 554, 3: 362}

[Agentic][Static Routing] Agent outputs BEFORE:
[Agentic] Agent 0 output: [[-0.11011115 -0.10513714  0.02789143  0.1465779 ]]
[Agentic] Agent 1 output: [[-0.70454437  1.0612257  -0.3235479   0.49998885]]
[Agentic] Agent 2 output: [[-0.7727957  -0.20665789  0.5489416   0.44136897]]
[Agentic] Agent 3 output: [[-0.397014    0.01314629 -0.3986143   0.54396534]]

[Agentic][Static Routing][Training] Agent 0 fine-tuning ...
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 45.853
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 0.766
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.227

[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:
[Agentic] Agent 0 output: [[ 3.6277854 -2.7561522 -2.6246474 -2.6003504]]
[Agentic] Agent 1 output: [[-0.70454437  1.0612257  -0.3235479   0.49998885]]
[Agentic] Agent 2 output: [[-0.7727957  -0.20665789  0.5489416   0.44136897]]
[Agentic] Agent 3 output: [[-0.397014    0.01314629 -0.3986143   0.54396534]]
[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.7544378698224852, 0.9926470588235294, 0.9922779922779923]

[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):
[Agentic][CAC] Individual Agent 0 output: tensor([[ 3.1359, -3.0678, -2.3237, -2.8724]])
[Agentic][CAC] Individual Agent 1 output: tensor([[-0.5840,  0.3092,  0.1111,  0.1341]])
[Agentic][CAC] Individual Agent 2 output: tensor([[-0.7986, -0.7899,  1.0808,  0.2882]])
[Agentic][CAC] Individual Agent 3 output: tensor([[-0.4020, -0.3466, -0.0848,  0.5532]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:

[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...
[Agentic][CAC][SharedMemory] Updating memory for agent 2.
[Agentic][CAC][SharedMemory] Updating memory for agent 0.
[Agentic][CAC] Aggregated output (learnable selection): tensor([[[ 1.1687, -1.9289, -0.6215, -1.2921]]])
[Agentic] Agents selected by coordinator: [2, 0]
[Agentic][CAC] Selected Agent 2 output: tensor([[-0.7986, -0.7899,  1.0808,  0.2882]])
[Agentic][CAC] Selected Agent 0 output: tensor([[ 3.1359, -3.0678, -2.3237, -2.8724]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

Round 2

[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.442 | LB: 0.055 | Router: 1.320 | Entropy: 1.278
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [632, 224, 307, 837]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2284787893295288, 0.2282133549451828, 0.21323220431804657, 0.3300755023956299]
[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.359 | LB: 0.012 | Router: 1.365 | Entropy: 1.358
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [599, 93, 282, 1026]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2425186187028885, 0.21849215030670166, 0.23428340256214142, 0.30470573902130127]
[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.332 | LB: 0.012 | Router: 1.347 | Entropy: 1.356
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [552, 125, 341, 982]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24458275735378265, 0.21734574437141418, 0.23352687060832977, 0.3045446276664734]
[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.294 | LB: 0.013 | Router: 1.302 | Entropy: 1.341
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [506, 192, 374, 928]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2456589788198471, 0.21766482293605804, 0.23197270929813385, 0.3047035336494446]
[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.221 | LB: 0.014 | Router: 1.221 | Entropy: 1.292
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [527, 305, 401, 767]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24822360277175903, 0.22112636268138885, 0.23225100338459015, 0.29839888215065]

[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent
tensor([[244, 151,  54,  28],
[ 27, 262,  32,  17],
[ 25,  79, 265,  39],
[ 81, 298, 127, 271]])
[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.6472148541114059, 0.3632911392405063, 0.5564853556485355, 0.7633802816901408]
[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 377, 1: 790, 2: 478, 3: 355}

[Agentic][Static Routing] Agent outputs BEFORE:
[Agentic] Agent 0 output: [[ 0.6931141  -0.19254029 -0.10226681  0.37421077]]
[Agentic] Agent 1 output: [[-0.4284616  -0.05967046 -0.06809097  0.09302867]]
[Agentic] Agent 2 output: [[-0.7964362 -0.7652833  0.6985868  0.6300565]]
[Agentic] Agent 3 output: [[-0.5297187  -0.60982245 -0.5000442   0.44182912]]

[Agentic][Static Routing][Training] Agent 0 fine-tuning ...
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 47.040
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 1.717
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.492

[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:
[Agentic] Agent 0 output: [[ 6.7630997 -3.4046059 -3.7899013 -2.9758308]]
[Agentic] Agent 1 output: [[-0.4284616  -0.05967046 -0.06809097  0.09302867]]
[Agentic] Agent 2 output: [[-0.7964362 -0.7652833  0.6985868  0.6300565]]
[Agentic] Agent 3 output: [[-0.5297187  -0.60982245 -0.5000442   0.44182912]]
[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.8402366863905325, 0.7475490196078431, 0.9987129987129987]

[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):
[Agentic][CAC] Individual Agent 0 output: tensor([[ 2.5327, -1.6020, -1.0732, -1.4507]])
[Agentic][CAC] Individual Agent 1 output: tensor([[-0.0360, -0.2209,  0.3537, -0.1043]])
[Agentic][CAC] Individual Agent 2 output: tensor([[-0.6468, -1.1658,  0.7840, -0.0709]])
[Agentic][CAC] Individual Agent 3 output: tensor([[-0.6168, -0.5153, -0.1196,  0.0395]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:

[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...
[Agentic][CAC][SharedMemory] Updating memory for agent 2.
[Agentic][CAC][SharedMemory] Updating memory for agent 3.
[Agentic][CAC] Aggregated output (learnable selection): tensor([[[-0.6318, -0.8405,  0.3322, -0.0157]]])
[Agentic] Agents selected by coordinator: [2, 3]
[Agentic][CAC] Selected Agent 2 output: tensor([[-0.6468, -1.1658,  0.7840, -0.0709]])
[Agentic][CAC] Selected Agent 3 output: tensor([[-0.6168, -0.5153, -0.1196,  0.0395]])
[Agentic][CAC] Mean (raw logits) predicted class: 2

Round 3

[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.383 | LB: 0.062 | Router: 1.305 | Entropy: 1.262
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [613, 189, 434, 764]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2516506314277649, 0.18897846341133118, 0.24060657620429993, 0.31876420974731445]
[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.340 | LB: 0.016 | Router: 1.367 | Entropy: 1.348
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [665, 123, 256, 956]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2474702000617981, 0.2173183560371399, 0.2351091057062149, 0.3001022934913635]
[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.307 | LB: 0.016 | Router: 1.320 | Entropy: 1.341
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [618, 125, 291, 966]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24412214756011963, 0.21801181137561798, 0.23639778792858124, 0.30146828293800354]
[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.273 | LB: 0.017 | Router: 1.272 | Entropy: 1.320
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [582, 215, 330, 873]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24151229858398438, 0.21821509301662445, 0.2379952371120453, 0.30227744579315186]
[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.203 | LB: 0.021 | Router: 1.185 | Entropy: 1.263
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [557, 300, 362, 781]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24337705969810486, 0.2201685756444931, 0.23484183847904205, 0.30161261558532715]

[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent
tensor([[232, 156,  45,  44],
[ 50, 239,  18,  31],
[ 56,  53, 227,  72],
[ 90, 202,  86, 399]])
[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.5420560747663551, 0.3676923076923077, 0.6037234042553191, 0.7307692307692307]
[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 428, 1: 650, 2: 376, 3: 546}

[Agentic][Static Routing] Agent outputs BEFORE:
[Agentic] Agent 0 output: [[ 0.14363949 -0.35127923 -0.2435807   0.16805106]]
[Agentic] Agent 1 output: [[-0.39317277  0.06466846 -0.29272872  0.10903752]]
[Agentic] Agent 2 output: [[-0.6404912  -1.1054591   1.2104195   0.63240474]]
[Agentic] Agent 3 output: [[-0.2696519  -0.5628307  -0.40842414  1.0639894 ]]

[Agentic][Static Routing][Training] Agent 0 fine-tuning ...
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 41.201
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 0.635
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.149

[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:
[Agentic] Agent 0 output: [[ 5.5686793 -4.006922  -3.331307  -3.3818846]]
[Agentic] Agent 1 output: [[-0.39317277  0.06466846 -0.29272872  0.10903752]]
[Agentic] Agent 2 output: [[-0.6404912  -1.1054591   1.2104195   0.63240474]]
[Agentic] Agent 3 output: [[-0.2696519  -0.5628307  -0.40842414  1.0639894 ]]
[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.9526627218934911, 0.7794117647058824, 1.0]

[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):
[Agentic][CAC] Individual Agent 0 output: tensor([[ 3.3873, -2.8507, -1.9954, -2.2012]])
[Agentic][CAC] Individual Agent 1 output: tensor([[-0.2367, -0.4723, -0.2744,  0.1832]])
[Agentic][CAC] Individual Agent 2 output: tensor([[-0.6640, -0.8487,  1.0672, -0.0419]])
[Agentic][CAC] Individual Agent 3 output: tensor([[-0.7453, -0.5976, -0.5645,  0.8736]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:

[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...
[Agentic][CAC][SharedMemory] Updating memory for agent 2.
[Agentic][CAC][SharedMemory] Updating memory for agent 0.
[Agentic][CAC] Aggregated output (learnable selection): tensor([[[ 1.3616, -1.8497, -0.4641, -1.1215]]])
[Agentic] Agents selected by coordinator: [2, 0]
[Agentic][CAC] Selected Agent 2 output: tensor([[-0.6640, -0.8487,  1.0672, -0.0419]])
[Agentic][CAC] Selected Agent 0 output: tensor([[ 3.3873, -2.8507, -1.9954, -2.2012]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

Round 4

[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.398 | LB: 0.057 | Router: 1.361 | Entropy: 1.269
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [611, 305, 357, 727]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2137640416622162, 0.23346593976020813, 0.2336888611316681, 0.3190811574459076]
[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.352 | LB: 0.013 | Router: 1.367 | Entropy: 1.354
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [627, 153, 206, 1014]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24198880791664124, 0.22063705325126648, 0.23376412689685822, 0.3036099970340729]
[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.335 | LB: 0.014 | Router: 1.349 | Entropy: 1.350
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [588, 172, 277, 963]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24191345274448395, 0.21858900785446167, 0.23609794676303864, 0.30339959263801575]
[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.305 | LB: 0.014 | Router: 1.321 | Entropy: 1.339
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [520, 253, 353, 874]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2426518201828003, 0.21836456656455994, 0.23716901242733002, 0.30181464552879333]
[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.261 | LB: 0.016 | Router: 1.269 | Entropy: 1.310
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [481, 311, 358, 850]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24298714101314545, 0.22107264399528503, 0.23206353187561035, 0.303876668214798]

[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent
tensor([[193, 164,  67,  53],
[ 36, 247,  33,  22],
[ 31,  84, 239,  54],
[ 65, 340, 118, 254]])
[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.5753846153846154, 0.40718562874251496, 0.5229759299781181, 0.6631853785900783]
[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 325, 1: 835, 2: 457, 3: 383}

[Agentic][Static Routing] Agent outputs BEFORE:
[Agentic] Agent 0 output: [[0.06087414 0.00382155 0.45451552 0.21630257]]
[Agentic] Agent 1 output: [[-0.23852764 -0.05532968 -0.24762572  0.29535425]]
[Agentic] Agent 2 output: [[-0.40941828 -1.2831886   0.9965908   0.28270978]]
[Agentic] Agent 3 output: [[-0.41993684 -0.4706924  -0.5775753   0.47297737]]

[Agentic][Static Routing][Training] Agent 0 fine-tuning ...
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 48.532
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 1.017
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.321

[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:
[Agentic] Agent 0 output: [[ 6.2952332 -4.2393064 -2.6208184 -2.6947765]]
[Agentic] Agent 1 output: [[-0.23852764 -0.05532968 -0.24762572  0.29535425]]
[Agentic] Agent 2 output: [[-0.40941828 -1.2831886   0.9965908   0.28270978]]
[Agentic] Agent 3 output: [[-0.41993684 -0.4706924  -0.5775753   0.47297737]]
[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.0, 0.7524509803921569, 1.0]

[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):
[Agentic][CAC] Individual Agent 0 output: tensor([[ 4.1511, -2.7663, -1.4043, -1.9707]])
[Agentic][CAC] Individual Agent 1 output: tensor([[-0.0295, -0.2772, -0.2095, -0.0134]])
[Agentic][CAC] Individual Agent 2 output: tensor([[-0.3521, -1.4374,  1.3028, -0.1457]])
[Agentic][CAC] Individual Agent 3 output: tensor([[-0.7709, -0.5432, -0.3450,  0.4907]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:

[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...
[Agentic][CAC][SharedMemory] Updating memory for agent 0.
[Agentic][CAC][SharedMemory] Updating memory for agent 3.
[Agentic][CAC] Aggregated output (learnable selection): tensor([[[ 1.6901, -1.6548, -0.8747, -0.7400]]])
[Agentic] Agents selected by coordinator: [0, 3]
[Agentic][CAC] Selected Agent 0 output: tensor([[ 4.1511, -2.7663, -1.4043, -1.9707]])
[Agentic][CAC] Selected Agent 3 output: tensor([[-0.7709, -0.5432, -0.3450,  0.4907]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

Round 5

[Agentic][Dynamic Routing][Training] Epoch 1 | CE: 1.418 | LB: 0.072 | Router: 1.295 | Entropy: 1.247
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [627, 138, 516, 719]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2396836280822754, 0.20570972561836243, 0.2349652498960495, 0.3196414113044739]
[Agentic][Dynamic Routing][Training] Epoch 2 | CE: 1.361 | LB: 0.015 | Router: 1.358 | Entropy: 1.350
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [666, 89, 231, 1014]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2457910031080246, 0.2177312970161438, 0.23370280861854553, 0.30277499556541443]
[Agentic][Dynamic Routing][Training] Epoch 3 | CE: 1.323 | LB: 0.015 | Router: 1.333 | Entropy: 1.346
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [626, 107, 318, 949]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.2408578097820282, 0.22088824212551117, 0.2361108511686325, 0.3021431565284729]
[Agentic][Dynamic Routing][Training] Epoch 4 | CE: 1.271 | LB: 0.016 | Router: 1.276 | Entropy: 1.326
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [598, 129, 355, 918]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24361948668956757, 0.22048905491828918, 0.2351730465888977, 0.3007183372974396]
[Agentic][Dynamic Routing][Training] Epoch 5 | CE: 1.223 | LB: 0.018 | Router: 1.200 | Entropy: 1.281
[Agentic][Dynamic Routing][Training] Hard assignment counts per agent: [567, 196, 378, 859]
[Agentic][Dynamic Routing][Training] Mean softmax probability per agent: [0.24517381191253662, 0.22319447994232178, 0.23227833211421967, 0.29935339093208313]

[Agentic][Dynamic Routing] Confusion Matrix: rows=True class, cols=Routed agent
tensor([[297,  58,  43,  79],
[110, 156,  24,  48],
[ 40,  23, 285,  60],
[125, 112, 112, 428]])
[Agentic][Dynamic Routing][Testing] Per-agent accuracy (handled samples): [0.5192307692307693, 0.44412607449856734, 0.6142241379310345, 0.6959349593495935]
[Agentic][Dynamic Routing][Testing] Final routing distribution: {0: 572, 1: 349, 2: 464, 3: 615}

[Agentic][Static Routing] Agent outputs BEFORE:
[Agentic] Agent 0 output: [[ 0.18854988 -0.63583314 -0.2946814   0.31569844]]
[Agentic] Agent 1 output: [[0.09884851 0.22254989 0.1946752  0.26245126]]
[Agentic] Agent 2 output: [[-0.83836895 -1.1631118   1.2584822   0.2695332 ]]
[Agentic] Agent 3 output: [[-0.5242375  -0.4091273  -0.44803646  0.5635157 ]]

[Agentic][Static Routing][Training] Agent 0 fine-tuning ...
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 1 | Loss: 40.005
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 2 | Loss: 0.819
[Agentic][Static Routing][Agent 0 Fine-Tuning] Epoch 3 | Loss: 0.220

[Agentic][Static Routing] Agent outputs AFTER agent 0 fine-tuning:
[Agentic] Agent 0 output: [[ 4.654058  -4.1888223 -4.13238   -3.0432615]]
[Agentic] Agent 1 output: [[0.09884851 0.22254989 0.1946752  0.26245126]]
[Agentic] Agent 2 output: [[-0.83836895 -1.1631118   1.2584822   0.2695332 ]]
[Agentic] Agent 3 output: [[-0.5242375  -0.4091273  -0.44803646  0.5635157 ]]
[Agentic][Static Routing][Testing] Per-agent accuracy (handled samples): [1.0, 0.9112426035502958, 0.9338235294117647, 1.0]

[Agentic][CAC][Parallel Aggregation] For input X[2], aggregate all 4 agents (Majority Voting & Softmax Mean):
[Agentic][CAC] Individual Agent 0 output: tensor([[ 3.9724, -3.7572, -3.3710, -2.4644]])
[Agentic][CAC] Individual Agent 1 output: tensor([[-0.0176,  0.1097,  0.2423,  0.1614]])
[Agentic][CAC] Individual Agent 2 output: tensor([[-0.5941, -1.0641,  1.3857, -0.1762]])
[Agentic][CAC] Individual Agent 3 output: tensor([[-0.7977, -0.2917, -0.0368,  0.1457]])
[Agentic][CAC] Mean (raw logits) predicted class: 0

[Agentic][CAC][Learnable Coordinator] Dynamic selection for input X[2]:

[Agentic][CAC][Learnable Coordinator] Selecting agents dynamically...
[Agentic][CAC][SharedMemory] Updating memory for agent 1.
[Agentic][CAC][SharedMemory] Updating memory for agent 3.
[Agentic][CAC] Aggregated output (learnable selection): tensor([[[-0.4077, -0.0910,  0.1027,  0.1536]]])
[Agentic] Agents selected by coordinator: [1, 3]
[Agentic][CAC] Selected Agent 1 output: tensor([[-0.0176,  0.1097,  0.2423,  0.1614]])
[Agentic][CAC] Selected Agent 3 output: tensor([[-0.7977, -0.2917, -0.0368,  0.1457]])
[Agentic][CAC] Mean (raw logits) predicted class: 3